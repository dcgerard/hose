<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>HOSE Examples • hose</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">hose</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="..//index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/sure_example.html">HOSE Examples</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="http://github.com/dcgerard/hose">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>HOSE Examples</h1>
                        <h4 class="author">David Gerard</h4>
            
            <h4 class="date">2017-07-12</h4>
          </div>

    
    
<div class="contents">
<div id="abstract" class="section level2">
<h2 class="hasAnchor">
<a href="#abstract" class="anchor"></a>Abstract</h2>
<p>This vignette will run through a couple examples on calculating higher-order spectral estimators (HOSE) and using SURE as an estimator selection procedure.</p>
</div>
<div id="generate-simulated-data-" class="section level2">
<h2 class="hasAnchor">
<a href="#generate-simulated-data-" class="anchor"></a>Generate Simulated Data.</h2>
<p>First, we’ll load the <code>hose</code> package and create some simulated data whose mean is actually low multilinear rank. <code>X</code> is a <span class="math inline">\(10 \times 10 \times 10\)</span> tensor that has multilinear rank <span class="math inline">\(2 \times 2 \times 2\)</span>. We use the <code>holq</code> function from the <code>tensr</code> package to simulate a tensor whose first two singular values along each mode are approximately equal.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(hose)
<span class="kw">set.seed</span>(<span class="dv">328</span>)

p &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">10</span>)
r &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>)
n &lt;-<span class="st"> </span><span class="kw">length</span>(p)
tau2 &lt;-<span class="st"> </span><span class="dv">1</span>
fnorm_mean &lt;-<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">prod</span>(p)) *<span class="st"> </span><span class="kw">sqrt</span>(tau2) /<span class="st"> </span><span class="dv">2</span> ## so on same order as error

U_temp &lt;-<span class="st"> </span>tensr::<span class="kw">hosvd</span>(<span class="kw">array</span>(stats::<span class="kw">rnorm</span>(<span class="kw">prod</span>(p)), <span class="dt">dim =</span> p))$U
U2_temp &lt;-<span class="st"> </span><span class="kw">list</span>()
S_temp &lt;-<span class="st"> </span>tensr::<span class="kw">holq</span>(<span class="kw">array</span>(stats::<span class="kw">rnorm</span>(<span class="kw">prod</span>(p)), <span class="dt">dim =</span> r), <span class="dt">print_diff =</span> <span class="ot">FALSE</span>)$Z
for(index in <span class="dv">1</span>:n) {
    U2_temp[[index]] &lt;-<span class="st"> </span>U_temp[[index]][ , <span class="dv">1</span>:r[index]]
}
## Our mean tensor.
Theta &lt;-<span class="st"> </span>tensr::<span class="kw">atrans</span>(S_temp, U2_temp)
Theta &lt;-<span class="st"> </span>Theta /<span class="st"> </span>tensr::<span class="kw">fnorm</span>(Theta) *<span class="st"> </span>fnorm_mean
hosvd_Theta &lt;-<span class="st"> </span>hose::<span class="kw"><a href="../reference/hosvd_full.html">hosvd_full</a></span>(Theta)

## Our data tensor
X &lt;-<span class="st"> </span>Theta +<span class="st"> </span><span class="kw">array</span>(stats::<span class="kw">rnorm</span>(<span class="dt">n =</span> <span class="kw">prod</span>(p), <span class="dt">sd =</span> <span class="kw">sqrt</span>(tau2)), <span class="dt">dim =</span> p)</code></pre></div>
<p>Some scree plots of the three matricizations of the data <code>X</code> do not seem to suggest that the mean tensor has low multilinear rank.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## scree plots of the modes. Doesn't look low rank.
hosvd_x &lt;-<span class="st"> </span><span class="kw"><a href="../reference/hosvd_full.html">hosvd_full</a></span>(X)
<span class="kw">par</span>(<span class="dt">cex.lab =</span> <span class="fl">0.7</span>, <span class="dt">cex.main =</span> <span class="fl">0.7</span>, <span class="dt">cex.axis =</span> <span class="fl">0.7</span>, <span class="dt">mgp =</span> <span class="kw">c</span>(<span class="fl">1.2</span>, <span class="fl">0.4</span>, <span class="dv">0</span>),
    <span class="dt">mar =</span> <span class="kw">c</span>(<span class="fl">2.2</span>, <span class="dv">2</span>, <span class="fl">1.8</span>, <span class="fl">0.5</span>))
for(index in <span class="dv">1</span>:n) {
    <span class="kw">plot</span>(hosvd_x$D[[index]], <span class="dt">type =</span> <span class="st">"h"</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="kw">max</span>(hosvd_x$D[[index]])),
         <span class="dt">xlab =</span> <span class="st">"Singular Value"</span>, <span class="dt">ylab =</span> <span class="st">"Value"</span>,
         <span class="dt">main =</span> <span class="kw">paste0</span>(<span class="st">"Scree Plot for Mode "</span>, index))
}</code></pre></div>
<p><img src="sure_example_files/figure-html/unnamed-chunk-2-1.png" width="672"><img src="sure_example_files/figure-html/unnamed-chunk-2-2.png" width="672"><img src="sure_example_files/figure-html/unnamed-chunk-2-3.png" width="672"></p>
</div>
<div id="estimating-the-variance-" class="section level2">
<h2 class="hasAnchor">
<a href="#estimating-the-variance-" class="anchor"></a>Estimating the Variance.</h2>
<p>All of these SURE-based mean estimators require that the variance be known. Since in most real-world applications, the variance is not known, I’ve provided a few methods to non-parametrically estimate the variance. These methods are implemented in the function <code>tensor_var_est</code>. The procedures available were all designed for matrix-variate data when the mean is low rank, so <code>tensor_var_est</code> applies these methods to each matricization of the data tensor and averages the resulting estimators. I’ll describe two of these methods now.</p>
<p>The method that seems to work the best in general situations is that of Choi et al (2014). They use a degrees of freedom corrected residual mean-squared error of a soft-thresholding estimator of the mean where the tuning parameter is chosen by a procedure akin to cross-validation. Use the <code>sig_method = "soft"</code> option in <code>tensor_var_est</code> to use this method. Note that sometimes the <code>softImpute</code> function will not converge and return a warning. The main downside to this method is that it can be very slow.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sig_soft_out &lt;-<span class="st"> </span><span class="kw"><a href="../reference/tensor_var_est.html">tensor_var_est</a></span>(X, <span class="dt">sig_method =</span> <span class="st">"soft"</span>)</code></pre></div>
<pre><code>## Mode 1 , Sigma Hat = 1.532088 
## Mode 2 , Sigma Hat = 1.486471 
## Mode 3 , Sigma Hat = 1.273809</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(sig_soft_out$sig2_est)</code></pre></div>
<pre><code>## [1] 1.430789</code></pre>
<p>A method that works very well when the multilinear rank is very small and works very poorly othwerwise is that of Gavish and Donoho (2014). Their estimator is based on an asymptotic framework where the rank of the mean and the signal to noise ratio remain constant while the size of the matrix increases. Since 2 (the rank) is much less than 10 (the dimension size), this procedure might work here. Use the option <code>sig_method = "mp"</code> in <code>tensor_var_est</code> to implement this method.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sig_mp_out &lt;-<span class="st"> </span><span class="kw"><a href="../reference/tensor_var_est.html">tensor_var_est</a></span>(X, <span class="dt">sig_method =</span> <span class="st">"mp"</span>)
<span class="kw">print</span>(sig_mp_out$sig2_est)</code></pre></div>
<pre><code>## [1] 1.088261</code></pre>
<p>We’ll use the estimator from <code>sig_mp_out</code> as our variance in what follows.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tau2_est &lt;-<span class="st"> </span>sig_mp_out$sig2_est</code></pre></div>
</div>
<div id="the-mode-specific-truncation-estimator-" class="section level2">
<h2 class="hasAnchor">
<a href="#the-mode-specific-truncation-estimator-" class="anchor"></a>The Mode-specific Truncation Estimator.</h2>
<p>First we’ll look at mode-specific truncation as a multilinear rank selection procedure, running through each possible multilinear rank using the function <code>sure_rank</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sure_rank_out &lt;-<span class="st"> </span><span class="kw"><a href="../reference/sure_rank.html">sure_rank</a></span>(X, <span class="dt">tau2 =</span> tau2_est)</code></pre></div>
<p><code>sure_rank</code> returns the multilinear rank that minimizes the SURE.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sure_rank_out$min_rank ## Estimated multilinear rank. Should be close to (2, 2, 2).</code></pre></div>
<pre><code>## [1] 2 2 2</code></pre>
<p>The profiled SURE for each mode demonstrates that <span class="math inline">\(2 \times 2 \times 2\)</span> is indeed the value that minimizes the SURE.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">cex.lab =</span> <span class="fl">0.7</span>, <span class="dt">cex.main =</span> <span class="fl">0.7</span>, <span class="dt">cex.axis =</span> <span class="fl">0.7</span>, <span class="dt">mgp =</span> <span class="kw">c</span>(<span class="fl">1.2</span>, <span class="fl">0.4</span>, <span class="dv">0</span>),
    <span class="dt">mar =</span> <span class="kw">c</span>(<span class="fl">2.2</span>, <span class="dv">2</span>, <span class="fl">1.8</span>, <span class="fl">0.5</span>), <span class="dt">pch =</span> <span class="st">"."</span>)
marg_1 &lt;-<span class="st"> </span>sure_rank_out$all_ranks[,<span class="dv">2</span>] ==<span class="st"> </span>sure_rank_out$min_rank[<span class="dv">2</span>] &amp;
<span class="st">  </span>sure_rank_out$all_ranks[,<span class="dv">3</span>] ==<span class="st"> </span>sure_rank_out$min_rank[<span class="dv">3</span>]
<span class="kw">plot</span>(sure_rank_out$all_ranks[,<span class="dv">1</span>], sure_rank_out$sure,
     <span class="dt">xlab =</span> <span class="st">"Mode 1 Rank"</span>, <span class="dt">ylab =</span> <span class="st">"SURE"</span>, <span class="dt">main =</span> <span class="st">"Mode 1 Rank vs SURE"</span>)
<span class="kw">lines</span>(sure_rank_out$all_ranks[marg_1,<span class="dv">1</span>], sure_rank_out$sure[marg_1],
      <span class="dt">lty =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="dv">2</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)
<span class="kw">legend</span>(<span class="st">"topright"</span>, <span class="st">"Other Modes at Min Value"</span>, <span class="dt">lty =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="dv">2</span>,
       <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">cex =</span> <span class="fl">0.7</span>)</code></pre></div>
<p><img src="sure_example_files/figure-html/unnamed-chunk-8-1.png" width="672"></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">marg_2 &lt;-<span class="st"> </span>sure_rank_out$all_ranks[,<span class="dv">1</span>] ==<span class="st"> </span>sure_rank_out$min_rank[<span class="dv">1</span>] &amp;
<span class="st">  </span>sure_rank_out$all_ranks[,<span class="dv">3</span>] ==<span class="st"> </span>sure_rank_out$min_rank[<span class="dv">3</span>]
<span class="kw">plot</span>(sure_rank_out$all_ranks[,<span class="dv">2</span>], sure_rank_out$sure,
     <span class="dt">xlab =</span> <span class="st">"Mode 2 Rank"</span>, <span class="dt">ylab =</span> <span class="st">"SURE"</span>, <span class="dt">main =</span> <span class="st">"Mode 2 Rank vs SURE"</span>)
<span class="kw">lines</span>(sure_rank_out$all_ranks[marg_2,<span class="dv">2</span>], sure_rank_out$sure[marg_2],
      <span class="dt">lty =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="dv">2</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)
<span class="kw">legend</span>(<span class="st">"topright"</span>, <span class="st">"Other Modes at Min Value"</span>, <span class="dt">lty =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="dv">2</span>,
       <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">cex =</span> <span class="fl">0.7</span>)</code></pre></div>
<p><img src="sure_example_files/figure-html/unnamed-chunk-8-2.png" width="672"></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">marg_3 &lt;-<span class="st"> </span>sure_rank_out$all_ranks[,<span class="dv">1</span>] ==<span class="st"> </span>sure_rank_out$min_rank[<span class="dv">1</span>] &amp;
<span class="st">  </span>sure_rank_out$all_ranks[,<span class="dv">2</span>] ==<span class="st"> </span>sure_rank_out$min_rank[<span class="dv">2</span>]
<span class="kw">plot</span>(sure_rank_out$all_ranks[,<span class="dv">3</span>], sure_rank_out$sure,
     <span class="dt">xlab =</span> <span class="st">"Mode 3 Rank"</span>, <span class="dt">ylab =</span> <span class="st">"SURE"</span>, <span class="dt">main =</span> <span class="st">"Mode 3 Rank vs SURE"</span>)
<span class="kw">lines</span>(sure_rank_out$all_ranks[marg_3,<span class="dv">3</span>], sure_rank_out$sure[marg_3],
      <span class="dt">lty =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="dv">2</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)
<span class="kw">legend</span>(<span class="st">"topright"</span>, <span class="st">"Other Modes at Min Value"</span>, <span class="dt">lty =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="dv">2</span>,
       <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">cex =</span> <span class="fl">0.7</span>)</code></pre></div>
<p><img src="sure_example_files/figure-html/unnamed-chunk-8-3.png" width="672"></p>
</div>
<div id="mode-specific-soft-thresholding-estimator-and-competitors-" class="section level2">
<h2 class="hasAnchor">
<a href="#mode-specific-soft-thresholding-estimator-and-competitors-" class="anchor"></a>Mode-specific Soft-thresholding Estimator and Competitors.</h2>
<p>We’ll switch gears now and fit a mode-specific soft-thresholding estimator. The optimal parameter values for the mode-specific soft-thresholding estimator can be found via <code>soft_coord</code>. The final mean estimate is <code>soft_coord$est</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">c_obj &lt;-<span class="st"> </span><span class="kw"><a href="../reference/get_c.html">get_c</a></span>(X)
lambda_init &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, n)
c_init &lt;-<span class="st"> </span><span class="dv">1</span>
soft_out &lt;-<span class="st"> </span><span class="kw"><a href="../reference/soft_coord.html">soft_coord</a></span>(c_obj, <span class="dt">lambda_init =</span> lambda_init, <span class="dt">c_init =</span> c_init,
                       <span class="dt">use_sure =</span> <span class="ot">TRUE</span>, <span class="dt">print_iter =</span> <span class="ot">FALSE</span>, <span class="dt">tau2 =</span> tau2_est, <span class="dt">itermax =</span> <span class="dv">20</span>)</code></pre></div>
<pre><code>##      SURE = 160.4 
##      SURE = 150.9 
##      SURE = 140.19 
##      SURE = 127.58 
##      SURE = 109.14 
##      SURE = 92.17 
##      SURE = 80.09 
##      SURE = 67.35 
##      SURE = 57.73 
##      SURE = 56.45 
##      SURE = 55.43 
##      SURE = 53.66 
##      SURE = 52.76 
##      SURE = 52.02 
##      SURE = 50.37 
##      SURE = 49.82 
##      SURE = 49.24 
##      SURE = 48.63 
##      SURE = 47.98</code></pre>
<p>We’ll compare the scree plots of the mean <span class="math inline">\(\Theta\)</span>, the data <span class="math inline">\(X\)</span>, and mode-specific soft-thresholding estimator.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## scree plots of resulting estimator, X, and Theta
hosvd_soft &lt;-<span class="st"> </span><span class="kw"><a href="../reference/hosvd_full.html">hosvd_full</a></span>(soft_out$est)

<span class="kw">par</span>(<span class="dt">cex.lab =</span> <span class="fl">0.7</span>, <span class="dt">cex.main =</span> <span class="fl">0.7</span>, <span class="dt">cex.axis =</span> <span class="fl">0.7</span>, <span class="dt">mgp =</span> <span class="kw">c</span>(<span class="fl">1.2</span>, <span class="fl">0.4</span>, <span class="dv">0</span>),
    <span class="dt">mar =</span> <span class="kw">c</span>(<span class="fl">2.2</span>, <span class="dv">2</span>, <span class="fl">1.8</span>, <span class="fl">0.5</span>), <span class="dt">pch =</span> <span class="st">"."</span>)
for(mode_index in <span class="dv">1</span>:n) {
    <span class="kw">plot</span>(hosvd_soft$D[[mode_index]], <span class="dt">type =</span> <span class="st">"h"</span>, <span class="dt">xlab =</span> <span class="st">"Singular Value"</span>,
         <span class="dt">ylab =</span> <span class="st">"Value"</span>, <span class="dt">main =</span> <span class="kw">paste0</span>(<span class="st">"Mode "</span>, mode_index, <span class="st">" Scree Plot"</span>),
         <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="kw">max</span>(<span class="kw">c</span>(hosvd_soft$D[[mode_index]],
                           hosvd_x$D[[mode_index]],
                           hosvd_Theta$D[[mode_index]]))))
    <span class="kw">lines</span>(<span class="dv">1</span>:p[mode_index] +<span class="st"> </span><span class="fl">0.2</span>, hosvd_x$D[[mode_index]], <span class="dt">type =</span> <span class="st">"h"</span>, <span class="dt">lty =</span> <span class="dv">2</span>)
    <span class="kw">lines</span>(<span class="dv">1</span>:p[mode_index] +<span class="st"> </span><span class="fl">0.4</span>, hosvd_Theta$D[[mode_index]], <span class="dt">type =</span> <span class="st">"h"</span>,
          <span class="dt">lty =</span> <span class="dv">3</span>)
    <span class="kw">legend</span>(<span class="st">"topright"</span>, <span class="kw">c</span>(<span class="st">"Soft"</span>, <span class="st">"X"</span>, <span class="st">"Theta"</span>), <span class="dt">lty =</span> <span class="dv">1</span>:<span class="dv">3</span>, <span class="dt">cex =</span> <span class="fl">0.7</span>)
}</code></pre></div>
<p><img src="sure_example_files/figure-html/unnamed-chunk-10-1.png" width="672"><img src="sure_example_files/figure-html/unnamed-chunk-10-2.png" width="672"><img src="sure_example_files/figure-html/unnamed-chunk-10-3.png" width="672"></p>
<p>We’ll compare our tensor estimator to a couple matrix and vector competitors. We’ll look at the soft-thresholding estimator of Candes et al (2013), Stein’s estimator (Stein, 1961), and a variant of the estimator of Efron and Morris (1972) that shrinks one mode, but chooses that mode by SURE.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">svd_mode1 &lt;-<span class="st"> </span><span class="kw">svd</span>(tensr::<span class="kw">mat</span>(X, <span class="dv">1</span>))
mat_optim &lt;-<span class="st"> </span><span class="kw">optim</span>(<span class="dv">1</span>, <span class="dt">fn =</span> sure_matrix, <span class="dt">d =</span> svd_mode1$d,
                   <span class="dt">p_dim =</span> <span class="kw">c</span>(p[<span class="dv">1</span>], <span class="kw">prod</span>(p[-<span class="dv">1</span>])), <span class="dt">tau2 =</span> tau2_est, <span class="dt">method =</span> <span class="st">"Brent"</span>,
                   <span class="dt">lower =</span> <span class="dv">0</span>, <span class="dt">upper =</span> svd_mode1$d[<span class="dv">1</span>])
mat_est &lt;-<span class="st"> </span><span class="kw">array</span>(svd_mode1$u %*%
<span class="st">                   </span><span class="kw">diag</span>(hose:::<span class="kw"><a href="../reference/pos_part.html">pos_part</a></span>(svd_mode1$d -<span class="st"> </span>mat_optim$par)) %*%
<span class="st">                   </span><span class="kw">t</span>(svd_mode1$v), <span class="dt">dim =</span> p)

final_stein &lt;-<span class="st"> </span><span class="kw"><a href="../reference/stein.html">stein</a></span>(X, tau2_est) ## Stein's estimator.
final_em &lt;-<span class="st"> </span><span class="kw"><a href="../reference/min_ef.html">min_ef</a></span>(X, tau2_est) ## Min Efron-Morris estimator.</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cat</span>(
    <span class="st">"                   Losses:"</span>, <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>,
    <span class="st">"         Truncated HOSVD:"</span>, <span class="kw">round</span>(tensr::<span class="kw">fnorm</span>(sure_rank_out$est -<span class="st"> </span>Theta)), <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>,
    <span class="st">"Tensor Soft Thresholding:"</span>, <span class="kw">round</span>(tensr::<span class="kw">fnorm</span>(soft_out$est -<span class="st"> </span>Theta)), <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>,
    <span class="st">"Matrix Soft Thresholding:"</span>, <span class="kw">round</span>(tensr::<span class="kw">fnorm</span>(mat_est -<span class="st"> </span>Theta)), <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>,
    <span class="st">"            Efron-Morris:"</span>, <span class="kw">round</span>(tensr::<span class="kw">fnorm</span>(final_em$ef_est -<span class="st"> </span>Theta)), <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>,
    <span class="st">"                   Stein:"</span>, <span class="kw">round</span>(tensr::<span class="kw">fnorm</span>(final_stein$est -<span class="st"> </span>Theta)), <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>,
    <span class="st">"                       X:"</span>, <span class="kw">round</span>(tensr::<span class="kw">fnorm</span>(X -<span class="st"> </span>Theta)), <span class="st">"</span><span class="ch">\n\n</span><span class="st">"</span>)</code></pre></div>
<pre><code>##                    Losses: 
##           Truncated HOSVD: 9 
##  Tensor Soft Thresholding: 9 
##  Matrix Soft Thresholding: 12 
##              Efron-Morris: 15 
##                     Stein: 14 
##                         X: 32</code></pre>
<p>Candes, E., Sing-Long, C. A., &amp; Trzasko, J. D. (2013). Unbiased risk estimates for singular value thresholding and spectral estimators. <em>Signal Processing, IEEE Transactions on</em>, 61(19), 4643-4657.</p>
<p>Choi, Y., Taylor, J., &amp; Tibshirani, R. (2014). Selecting the number of principal components: Estimation of the true rank of a noisy matrix. <em>arXiv preprint</em> arXiv:1410.8260.</p>
<p>Efron, B., &amp; Morris, C. (1972). Empirical Bayes on vector observations: An extension of Stein’s method. <em>Biometrika</em>, 59(2), 335-347.</p>
<p>Gavish, M., &amp; Donoho, D. L. (2014). The optimal hard threshold for singular values is 4/sqrt(3). <em>Information Theory, IEEE Transactions on</em>, 60(8), 5040-5053.</p>
<p>Gerard, D., &amp; Hoff, P. (2015). Adaptive Higher-order Spectral Estimators. <em>arXiv preprint</em> arXiv:1505.02114.</p>
<p>James, W., &amp; Stein, C. (1961, June). Estimation with quadratic loss. <em>In Proceedings of the fourth Berkeley symposium on mathematical statistics and probability</em> (Vol. 1, No. 1961, pp. 361-379).</p>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#abstract">Abstract</a></li>
      <li><a href="#generate-simulated-data-">Generate Simulated Data.</a></li>
      <li><a href="#estimating-the-variance-">Estimating the Variance.</a></li>
      <li><a href="#the-mode-specific-truncation-estimator-">The Mode-specific Truncation Estimator.</a></li>
      <li><a href="#mode-specific-soft-thresholding-estimator-and-competitors-">Mode-specific Soft-thresholding Estimator and Competitors.</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by David Gerard.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
