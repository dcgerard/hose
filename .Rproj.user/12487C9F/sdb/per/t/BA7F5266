{
    "collab_server" : "",
    "contents" : "##' Higher-order SVD using same signed eigenvectors as matix SVD's.\n##'\n##' Calculates the left singular vectors of each matrix unfolding of an array,\n##' then calculates the core array. The resulting output is a Tucker\n##' decomposition.\n##'\n##' \\code{Y} is equal to \\code{atrans(S, U)}, up to numerical accuracy.\n##'\n##' This function differs\n##' from the \\code{hosvd} function in the package \\code{tensr} only in  (1) the sign\n##' conditions on the core array and (2) it will also return the mode-specific singular values.\n##'\n##  More details on the HOSVD can be found in\n##' \\href{http://epubs.siam.org/doi/abs/10.1137/S0895479896305696}{ De Lathauwer\n##' et. al. (2000)}.\n##'\n##' @references De Lathauwer, L., De Moor, B., & Vandewalle, J. (2000).\n##'   \\href{http://epubs.siam.org/doi/abs/10.1137/S0895479896305696}{A\n##'   multilinear singular value decomposition}. \\emph{SIAM journal on Matrix\n##'   Analysis and Applications}, 21(4), 1253-1278.\n##'\n##' @return \\code{U} A list of matrices with orthonormal columns. Each matrix\n##'   contains the mode-specific singular vectors of its mode.\n##'\n##'   \\code{D} A list of vectors of numerics. The \\eqn{k}th vector contains the mode-specific singular\n##'   values of the \\eqn{k}th matricization of \\code{Y}\n##'\n##'   \\code{S}An all-orthogonal array. This is the core array from the HOSVD.\n##'\n##'\n##' @author David Gerard.\n##'\n##' @export\nhosvd_full <- function(Y) {\n    ## this function is required for sure() below higher order svd\n    m <- dim(Y)\n    K <- length(m)\n\n    ## get standard tsvd\n    U <- list()\n    D <- list()\n    D_inv <- list()\n    for (k in 1:K) {\n        X_k_svd <- svd(tensr::mat(Y, k))\n        U[[k]] <- X_k_svd$u\n        D[[k]] <- X_k_svd$d\n        D_inv[[k]] <- 1 / X_k_svd$d\n    }\n    S <- tensr::atrans(Y, lapply(U, t))\n    return(list(U = U, D = D, S = S))\n}\n\n##' Sums elements in a list.\n##'\n##' @param D A list of summable elements.\n##'\n##' @return \\code{list_sum} The sum of the elements in \\code{D}.\n##'\n##' @author David Gerard.\nlistSum <- function(D) {\n    list_sum <- D[[1]]\n    for (list_index in 2:length(D)) {\n        list_sum <- list_sum + D[[list_index]]\n    }\n    return(list_sum)\n}\n\n## mode specific functions------------------------------------------\n\n##' Outputs the 'C' array from Gerard and Hoff (2015), along with the HOSVD of\n##' the data tensor.\n##'\n##' This is necessary to calculate the SURE for higher-order spectral\n##' estimators.\n##'\n##' this function only calculates C and the HOSVD so that calculating SURE is\n##' faster when doing it over and over again\n##'\n##' @param X An array of numerics. The data.\n##'\n##' @return \\code{C_array} An array of numerics. The \"C\" array from Gerard and\n##'   Hoff (2015).\n##'\n##'   \\code{hosvd_x} A list containing the higher-order SVD of \\code{X}.\n##'\n##' @author David Gerard.\n##'\n##' @references Gerard, D., & Hoff, P. (2015).\n##'   \\href{http://arxiv.org/abs/1505.02114}{Adaptive Higher-order Spectral\n##'   Estimators}. \\emph{arXiv preprint} arXiv:1505.02114.\n##'\n##' @seealso \\code{\\link{diverge_given_c}} for calculating the divergence of\n##'   higher-order spectral estimators using the output of \\code{get_c}.\n##'\n##'   \\code{\\link{sure_given_c}} for calculating the SURE given the output of\n##'   \\code{get_c}.\n##'\n##'   \\code{\\link{sure}} for a wrapper for \\code{get_c} and\n##'   \\code{\\link{sure_given_c}}.\n##'\n##'   \\code{\\link{soft_coord}} for a coordinate descent algorithm for finding\n##'   the optimal sure using the output from \\code{get_c}.\n##'\n##' @export\nget_c <- function(X) {\n\n    p <- dim(X)\n    n <- length(p)\n\n    hosvd_x <- hosvd_full(X)\n\n    S <- hosvd_x$S\n\n    for (mode_index in 1:n) {\n        over_temp <- rep(NA, length = p[mode_index])\n        for (individual_index in 1:p[mode_index]) {\n            over_temp[individual_index] <-\n              sum(1 / (hosvd_x$D[[mode_index]] ^ 2 -\n                         hosvd_x$D[[mode_index]][individual_index] ^\n                         2)[-individual_index])\n        }\n        if (mode_index == 1) {\n            sig_inv_sq_array <- 1 / hosvd_x$D[[1]] ^ 2\n            sig_leave_one_out <- over_temp\n        } else {\n            sig_inv_sq_array <-\n              outer(sig_inv_sq_array,\n                    1 / hosvd_x$D[[mode_index]] ^ 2, FUN = \"+\")\n            sig_leave_one_out <- outer(sig_leave_one_out, over_temp, FUN = \"+\")\n        }\n    }\n\n    D_list <- list()\n    for (k_index in 1:n) {\n        k_temp_mat <- matrix(NA, nrow = p[k_index], ncol = prod(p[-k_index]))\n        for (i_index in 1:p[k_index]) {\n            mult_left <- 1 / (hosvd_x$D[[k_index]][i_index] ^ 2 -\n                                hosvd_x$D[[k_index]] ^ 2)\n            if (p[k_index] > 2) {\n                k_temp_mat[i_index, ] <-\n                  colSums((mult_left * tensr::mat(S ^ 2, k_index))[-i_index, ])\n            } else {\n                k_temp_mat[i_index, ] <-\n                  (mult_left * tensr::mat(S ^ 2, k_index))[-i_index, ]\n            }\n        }\n        k_temp_array <- array(k_temp_mat, dim = c(p[k_index], p[-k_index]))\n        D_list[[k_index]] <-\n          aperm(k_temp_array, match(1:n, c(k_index, (1:n)[-k_index])))\n    }\n\n    ## an array of ones\n    one_array <- array(1, dim = p)\n\n    C_array <- one_array - S ^ 2 * (sig_inv_sq_array + sig_leave_one_out) +\n      listSum(D_list)\n\n    return(list(C_array = C_array, hosvd_x = hosvd_x))\n}\n\n##' Calculates divergence of HOSE.\n##'\n##' Assumes we already did all of the heavy lifting in calculating the HOSVD and\n##' the 'C' matrix from my write-up 'sure_pdf'. Call \\code{\\link{get_c}} before\n##' using this function.\n##'\n##' @inheritParams sure_given_c\n##'\n##' @return \\code{divergence_f} The divergence of the higher-order spectral\n##'   estimator.\n##'\n##'   \\code{mean_est} The mean estimate of the higher-order spectral estimator.\n##'\n##' @author David Gerard.\n##'\n##' @references Gerard, D., & Hoff, P. (2015).\n##'   \\href{http://arxiv.org/abs/1505.02114}{Adaptive Higher-order Spectral\n##'   Estimators}. \\emph{arXiv preprint} arXiv:1505.02114.\n##'\n##' @seealso \\code{\\link{get_c}}, \\code{\\link{sure_given_c}}.\n##'\n##' @export\ndiverge_given_c <- function(obj, func, dfunc, lambda) {\n    hosvd_x <- obj$hosvd_x\n    C_array <- obj$C_array\n\n    S <- hosvd_x$S\n\n    p <- dim(S)\n    n <- length(p)\n\n    D <- list()\n    D_inv <- list()\n    f_D <- list()\n    df_D <- list()\n    for (mode_index in 1:n) {\n        D[[mode_index]] <- diag(hosvd_x$D[[mode_index]])\n        D_inv[[mode_index]] <- diag(1 / hosvd_x$D[[mode_index]])\n        f_D[[mode_index]] <-\n          diag(do.call(func[[mode_index]],\n                       args = list(hosvd_x$D[[mode_index]],\n                                   lambda[[mode_index]])))\n        df_D[[mode_index]] <-\n          diag(do.call(dfunc[[mode_index]],\n                       list(hosvd_x$D[[mode_index]], lambda[[mode_index]])))\n    }\n\n    f_d_inv <- list()\n    for (mode_index in 1:n) {\n        f_d_inv[[mode_index]] <- f_D[[mode_index]] * D_inv[[mode_index]]\n    }\n\n\n    H_list <- list()\n    for (mode_index in 1:n) {\n        H_list[[mode_index]] <- f_d_inv\n        H_list[[mode_index]][[mode_index]] <-\n          df_D[[mode_index]] * D_inv[[mode_index]] ^ 2\n    }\n\n    divergence_f <- sum(tensr::atrans(C_array, f_d_inv))\n    for (mode_index in 1:n) {\n        divergence_f <- divergence_f +\n          sum(tensr::atrans(S ^ 2, H_list[[mode_index]]))\n    }\n\n    mean_est <- tensr::atrans(tensr::atrans(S, f_d_inv), hosvd_x$U)\n\n    return(list(divergence_f = divergence_f, mean_est = mean_est))\n}\n\n##' Calculates SURE given the output of \\code{\\link{get_c}}.\n##'\n##' Calculates SURE assuming we already did all of the heavy lifting in\n##' calculating the HOSVD and the 'C' matrix from my write-up 'sure_pdf'. Call\n##' \\code{\\link{get_c}} before using this function.\n##'\n##' @param obj Output from \\code{\\link{get_c}}.\n##' @param func A list of length \\code{length(dim(X))} of shrinkage functions.\n##' @param dfunc A list of length \\code{length(dim(X))} of corresponding\n##'   derivative functions.\n##' @param lambda A list of parameter values for shinking along each mode.\n##' @param tau2 A positive numeric. The variance. Assumed known and defaults to\n##'   1.\n##'\n##' @author David Gerard.\n##'\n##' @references Gerard, D., & Hoff, P. (2015).\n##' \\href{http://arxiv.org/abs/1505.02114}{Adaptive Higher-order Spectral Estimators}.\n##' \\emph{arXiv preprint} arXiv:1505.02114.\n##'\n##' @seealso \\code{\\link{get_c}}, \\code{\\link{diverge_given_c}}, \\code{\\link{sure}}.\n##'\n##' @export\nsure_given_c <- function(obj, func, dfunc, lambda, tau2 = 1) {\n    hosvd_x <- obj$hosvd_x\n    C_array <- obj$C_array\n\n    S <- hosvd_x$S\n\n    p <- dim(S)\n    n <- length(p)\n\n    D <- list()\n    D_inv <- list()\n    f_D <- list()\n    df_D <- list()\n    for (mode_index in 1:n) {\n        D[[mode_index]] <- diag(hosvd_x$D[[mode_index]])\n        D_inv[[mode_index]] <- diag(1 / hosvd_x$D[[mode_index]])\n        f_D[[mode_index]] <-\n          diag(do.call(func[[mode_index]],\n                       args = list(hosvd_x$D[[mode_index]],\n                                   lambda[[mode_index]])))\n        df_D[[mode_index]] <-\n          diag(do.call(dfunc[[mode_index]], list(hosvd_x$D[[mode_index]],\n                                                 lambda[[mode_index]])))\n    }\n\n    f_d_inv <- list()\n    for (mode_index in 1:n) {\n        f_d_inv[[mode_index]] <- f_D[[mode_index]] * D_inv[[mode_index]]\n    }\n\n\n    H_list <- list()\n    for (mode_index in 1:n) {\n        H_list[[mode_index]] <- f_d_inv\n        H_list[[mode_index]][[mode_index]] <-\n          df_D[[mode_index]] * D_inv[[mode_index]] ^ 2\n    }\n\n    divergence_f <- sum(tensr::atrans(C_array, f_d_inv))\n    for (mode_index in 1:n) {\n        divergence_f <- divergence_f +\n          sum(tensr::atrans(S ^ 2, H_list[[mode_index]]))\n    }\n\n    rss <- sum((tensr::atrans(S, f_d_inv) - S) ^ 2)\n    sure_val <- 2 * tau2 * divergence_f + rss - tau2 * prod(p)\n    ## gsure_val <- (rss / prod(p)) / (1 - divergence_f / prod(p)) ^ 2\n    gsure_val <- rss / (1 - divergence_f / prod(p)) ^ 2\n    mean_est <- tensr::atrans(tensr::atrans(S, f_d_inv), hosvd_x$U)\n    return(list(sure_val = sure_val, gsure_val = gsure_val,\n                mean_est = mean_est))\n}\n\n##' Wrapper for \\code{\\link{get_c}} and \\code{\\link{sure_given_c}}.\n##'\n##' @inheritParams get_c\n##' @inheritParams sure_given_c\n##'\n##' @author David Gerard.\n##'\n##' @references Gerard, D., & Hoff, P. (2015).\n##'   \\href{http://arxiv.org/abs/1505.02114}{Adaptive Higher-order Spectral\n##'   Estimators}. \\emph{arXiv preprint} arXiv:1505.02114.\n##'\n##' @seealso \\code{\\link{get_c}}, \\code{\\link{sure_given_c}}.\n##'\n##' @export\nsure <- function(X, func, dfunc, lambda, tau2 = 1) {\n    ## wrapper for get_c and sure_given_c\n    C_output <- get_c(X)\n    return(sure_given_c(obj = C_output, func, dfunc, lambda, tau2 = tau2))\n}\n\n##' Truncation spectral function.\n##'\n##' @param x A vector of numerics.\n##' @param r A positive integer.\n##'\n##' @seealso \\code{\\link{df_truncate}}.\n##'\n##' @author David Gerard.\n##'\n##' @export\nf_truncate <- function(x, r) {\n    n <- length(x)\n    y <- rep(0, length = n)\n    y[1:r] <- x[1:r]\n    return(y)\n}\n\n##' Derivative of truncation spectral function.\n##'\n##' @inheritParams f_truncate\n##'\n##' @seealso \\code{\\link{f_truncate}}.\n##'\n##' @author David Gerard.\n##'\n##' @export\ndf_truncate <- function(x, r) {\n    n <- length(x)\n    y <- rep(0, length = n)\n    y[1:r] <- 1\n    return(y)\n}\n\n##' Iterates through all multilinear ranks less than \\code{max_nrank} and\n##' returns all SUREs.\n##'\n##'\n##' Iterate through all ranks less than max_nrank and choose rank with smallest\n##' sure.\n##'\n##' @param X An array of numerics. The data.\n##' @param max_nrank A vector of positive integers. The maximum rank to inspect for each mode.\n##' @param tau2 The variance, assumed known. Defaults to 1.\n##'\n##' @return \\code{min_rank} The multilinear rank that minimizes the SURE.\n##'\n##' \\code{min_sure} The minimum SURE value.\n##'\n##' \\code{sure_vec} A vector of all the SURE values of all the multilinear ranks that were inspected.\n##'\n##' \\code{all_ranks} A matrix of all of the multilinear ranks that were inspected.\n##'\n##' \\code{est} The final mean estimate.\n##'\n##' @author David Gerard.\n##'\n##' @references Gerard, D., & Hoff, P. (2015).\n##' \\href{http://arxiv.org/abs/1505.02114}{Adaptive Higher-order Spectral Estimators}.\n##' \\emph{arXiv preprint} arXiv:1505.02114.\n##'\n##' @export\nsure_rank <- function(X, max_nrank = dim(X), tau2 = 1) {\n    p <- dim(X)\n    n <- length(p)\n    func <- list()\n    dfunc <- list()\n    for (mode_index in 1:n) {\n        func[[mode_index]] <- f_truncate\n        dfunc[[mode_index]] <- df_truncate\n    }\n    C_output <- get_c(X)\n    all_ranks <- expand.grid(lapply(max_nrank, seq, from = 1))\n    sure_vec <- rep(NA, length = prod(max_nrank))\n    for (index in 1:prod(max_nrank)) {\n        sure_vec[index] <-\n          sure_given_c(C_output, func, dfunc,\n                       all_ranks[index, ], tau2 = tau2)$sure_val\n    }\n    which_rank_min <- which.min(sure_vec)\n\n\n\n    min_rank <- c(as.matrix(all_ranks[which_rank_min, ]))\n    min_sure <- sure_vec[which_rank_min]\n\n    est <- sure_given_c(C_output, func = func, dfunc = dfunc,\n                        lambda = min_rank, tau2 = tau2)$mean_est\n\n    return(list(min_rank = min_rank, min_sure = min_sure,\n                sure_vec = sure_vec, all_ranks = all_ranks, est = est))\n}\n\n##' Positive part function.\n##'\n##' Returns a vector whose elements are the positive parts of the elements of\n##' \\code{x}.\n##'\n##' @param x A vector of numerics.\n##'\n##' @author David Gerard.\npos_part <- function(x) {\n    return(sapply(x, max, 0))\n}\n\n##' Soft thresholding shrinkage function. Same as lasso for spectral shrinkage.\n##'\n##' @param A vector of numerics.\n##' @param lambda A numeric. The threshholding parameter.\n##'\n##' @seealso \\code{\\link{df_lasso}}.\n##'\n##' @author David Gerard.\n##'\n##' @export\nf_lasso <- function(x, lambda) {\n    return(pos_part(x - lambda))\n}\n\n##' Derivative of soft thresholding shrinkage function.\n##'\n##' @inheritParams f_lasso\n##'\n##' @seealso \\code{\\link{f_lass}}.\n##'\n##' @author David Gerard.\n##'\n##' @export\ndf_lasso <- function(x, lambda) {\n    y <- rep(1, length = length(x))\n    y[x < lambda] <- 0\n    return(y)\n}\n\n##' Scaling and soft thresholding shrinkage function.\n##'\n##' @param x A vector of numerics.\n##' @param params A vector of length 2 of numerics. \\code{param[1]} is the\n##'   scaling parameter, \\code{param[2]} is the threshholding parameter.\n##'\n##' @seealso \\code{\\link{df_lasso_mult}}.\n##'\n##' @author David Gerard.\n##'\n##' @export\nf_lasso_mult <- function(x, params) {\n    lambda <- params[1]\n    const <- params[2]\n    return(const * pos_part(x - lambda))\n}\n\n##' Derivative of scaling and soft thresholding shrinkage function.\n##'\n##'\n##' @inheritParams f_lasso_mult\n##'\n##' @seealso \\code{\\link{f_lasso_mult}}.\n##'\n##' @author David Gerard.\n##'\n##' @export\ndf_lasso_mult <- function(x, params) {\n    lambda <- params[1]\n    const <- params[2]\n    y <- rep(const, length = length(x))\n    y[x < lambda] <- 0\n    return(y)\n}\n\n############################### These functions shrink S directly\n\n##' Positive part function.\n##'\n##' Returns an object whose elements are the positive parts of the elements of\n##' \\code{X}.\n##'\n##' @param X A vector, matrix, or array of numerics.\n##'\n##'\n##' @author David Gerard.\npos_part_2 <- function(X) {\n    X[X < 0] <- 0\n    return(X)\n}\n\n##' Soft thresholding a core array.\n##'\n##' @param S An array of numerics.\n##' @param lambda A numeric. The threshholding parameter.\n##'\n##' @seealso \\code{\\link{df_S_lasso}}.\n##'\n##' @author David Gerard.\n##'\n##' @export\nf_S_lasso <- function(S, lambda) {\n    ## lasso typo estimator\n    S_new <- sign(S) * pos_part_2(abs(S) - lambda)\n    return(S_new)\n}\n\n##' Derivative of soft thresholding a core array.\n##'\n##' @inheritParams f_S_lasso\n##'\n##' @seealso \\code{\\link{df_S_lasso}}.\n##'\n##' @author David Gerard.\n##'\n##' @export\ndf_S_lasso <- function(S, lambda) {\n    ## derivative of lasso type estimator\n    diff_S <- array(1, dim = dim(S))\n    diff_S[abs(S) < lambda] <- 0\n    return(diff_S)\n}\n\n##' Scaling and soft thresholding a core array.\n##'\n##' @param S An array of numerics.\n##' @param params A vector of length 2 of numerics. \\code{param[1]} is the\n##'   scaling parameter, \\code{param[2]} is the threshholding parameter.\n##'\n##' @seealso \\code{\\link{df_S_lasso_mult}}.\n##'\n##' @author David Gerard.\n##'\n##' @export\nf_S_lasso_mult <- function(S, params) {\n    ## lasso typo estimator\n    lambda <- params[1]\n    const <- params[2]\n    S_new <- const * sign(S) * pos_part_2(abs(S) - lambda)\n    return(S_new)\n}\n\n##' Derivative of scaling and soft thresholding a core array.\n##'\n##' @inheritParams f_S_lasso_mult\n##'\n##' @seealso \\code{\\link{df_S_lasso_mult}}.\n##'\n##' @author David Gerard.\n##'\n##' @export\ndf_S_lasso_mult <- function(S, params) {\n    ## lasso typo estimator\n    lambda <- params[1]\n    const <- params[2]\n    diff_S <- const * array(1, dim = dim(S))\n    diff_S[abs(S) < lambda] <- 0\n    return(diff_S)\n}\n\n##' Calculates necessary components to calculate the SURE for estimators that\n##' shrink the individual elements of the core array.\n##'\n##' @param X An array of numerics. The tensor data.\n##'\n##' @return A list of objects meant to be fed into\n##'   \\code{\\link{sure_given_basics}} to calculate the SURE for higher-order\n##'   spectral estimators that shrink the core array directly.\n##'\n##' @author David Gerard.\n##'\n##' @seealso \\code{\\link{sure_given_basics}}, \\code{\\link{sure_S}}\n##'\n##' @references Gerard, D., & Hoff, P. (2015).\n##'   \\href{http://arxiv.org/abs/1505.02114}{Adaptive Higher-order Spectral\n##'   Estimators}. \\emph{arXiv preprint} arXiv:1505.02114.\n##'\n##' @export\nget_basics <- function(X) {\n    p <- dim(X)\n    hosvd_x <- hosvd_full(X)\n\n    sum_array <- list()\n    for (mode_index in 1:length(p)) {\n        s_k_mat <- matrix(NA, nrow = p[mode_index], ncol = prod(p[-mode_index]))\n        for (i_index in 1:p[mode_index]) {\n            if (p[mode_index] > 2) {\n                s_k_mat[i_index, ] <-\n                  colSums((1 / (hosvd_x$D[[mode_index]][i_index] ^ 2 -\n                                  hosvd_x$D[[mode_index]] ^ 2) *\n                             tensr::mat(hosvd_x$S ^ 2, mode_index))[-i_index, ])\n            } else {\n                s_k_mat[i_index, ] <-\n                  (1 / (hosvd_x$D[[mode_index]][i_index] ^ 2 -\n                          hosvd_x$D[[mode_index]] ^ 2) *\n                     tensr::mat(hosvd_x$S ^ 2, mode_index))[-i_index, ]\n            }\n        }\n        s_k_temp_array <-\n          array(s_k_mat, dim = c(p[mode_index], p[-mode_index]))\n        sum_array[[mode_index]] <-\n          aperm(s_k_temp_array,\n                match(1:length(p), c(mode_index, (1:length(p))[-mode_index])))\n    }\n    S_mult <- listSum(sum_array)\n\n\n    sig_list <- list()\n    for (mode_index in 1:length(p)) {\n        sig_list[[mode_index]] <- rep(NA, length = p[mode_index])\n        for (i_index in 1:p[mode_index]) {\n            sig_list[[mode_index]][i_index] <-\n              sum( (1 / (hosvd_x$D[[mode_index]][i_index] ^ 2 -\n                           hosvd_x$D[[mode_index]] ^ 2))[-i_index])\n        }\n        if (mode_index == 1) {\n            sig_leave_one_out <- sig_list[[mode_index]]\n        } else {\n            sig_leave_one_out <-\n              outer(sig_leave_one_out, sig_list[[mode_index]], FUN = \"+\")\n        }\n    }\n    s_s_array <- sig_leave_one_out * hosvd_x$S\n\n    return(list(hosvd_x = hosvd_x, s_s_array = s_s_array, S_mult = S_mult))\n}\n\n##' Calculates the SURE for estimators that shrink the individual elements of\n##' the core array.\n##'\n##' @param c_obj The output from \\code{\\link{get_basics}}.\n##' @param func A shrinkage function.\n##' @param dfunc The derivative function of \\code{func}.\n##' @param params The parameters to be fed into \\code{func} and \\code{dfunc}.\n##' @param tau2 A positive numeric. The variance. Assumed known and defaults to\n##'   1.\n##'\n##' @return \\code{sure_val} The sure value of the higher-order spectral\n##'   estimator.\n##'\n##'   \\code{est} The mean estimate.\n##'\n##' @author David Gerard.\n##'\n##' @references Gerard, D., & Hoff, P. (2015).\n##'   \\href{http://arxiv.org/abs/1505.02114}{Adaptive Higher-order Spectral\n##'   Estimators}. \\emph{arXiv preprint} arXiv:1505.02114.\n##'\n##' @seealso \\code{\\link{get_basics}}, \\code{\\link{sure_S}}.\n##'\n##' @export\nsure_given_basics <- function(c_obj, func, dfunc, params, tau2 = 1) {\n    ## c_obj: object returned from get_basics() tau2: known variance\n    hosvd_x <- c_obj$hosvd_x\n    s_s_array <- c_obj$s_s_array\n    S_mult <- c_obj$S_mult\n\n    p <- dim(s_s_array) ## need to check this.\n\n    s_new <- func(hosvd_x$S, params)\n    diff_S <- dfunc(hosvd_x$S, params)\n    est <- tensr::atrans(s_new, hosvd_x$U)\n    divergence_f <- sum(s_s_array * s_new + diff_S * (1 + S_mult))\n\n    sure_val <- -tau2 * prod(p) + 2 * tau2 * divergence_f +\n      sum( (s_new - hosvd_x$S) ^ 2)\n    return(list(sure_val = sure_val, est = est))\n}\n\n\n##' Wrapper for \\code{\\link{get_basics}} and \\code{\\link{sure_given_basics}}.\n##'\n##' @inheritParams get_basics\n##' @inheritParams sure_given_basics\n##'\n##' @return \\code{sure_val} The sure value of the higher-order spectral\n##'   estimator.\n##'\n##'   \\code{est} The mean estimate.\n##'\n##' @author David Gerard.\n##'\n##' @references Gerard, D., & Hoff, P. (2015).\n##'   \\href{http://arxiv.org/abs/1505.02114}{Adaptive Higher-order Spectral\n##'   Estimators}. \\emph{arXiv preprint} arXiv:1505.02114.\n##'\n##' @seealso \\code{\\link{get_basics}}, \\code{\\link{sure_given_basics}}.\n##'\n##' @export\nsure_S <- function(X, func, dfunc, params, tau2 = 1) {\n    c_obj <- get_basics(X)\n    sure_given_basics(c_obj, func, dfunc, params, tau2)\n}\n\n############### Competitors\n\n##' SURE for spectral shrinkage functions for complex matrices.\n##'\n##' @param d A vector of numerics. The singular values.\n##' @param lambda A numeric. The shrinkage parameter.\n##' @param p A vector of positive integers. The dimension of the data array.\n##' @param tau2 A positive numeric. The variance. Assumed known and defaults to\n##'   1.\n##'\n##' @author David Gerard\n##'\n##' @references Candes, E., Sing-Long, C. A., & Trzasko, J. D. (2013).\n##'   \\href{http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6545395&tag=1}{Unbiased\n##'    risk estimates for singular value thresholding and spectral estimators}.\n##'   \\emph{Signal Processing, IEEE Transactions on}, 61(19), 4643-4657.\n##'\n##' @export\nsure_matrix_complex <- function(d, lambda, p, tau2 = 1) {\n\n    f_d <- pos_part(d - lambda)\n    df_d <- 1 * (d > lambda)\n\n    max_d_lambda <- sapply(d, min, lambda)\n    outer_temp <- 1 / outer(d ^ 2, d ^ 2, \"-\")\n    diag(outer_temp) <- 0\n    right_mult <- apply(outer_temp, 1, sum)\n    div_f <- sum(df_d + (2 * abs(p[1] - p[2]) + 1) * f_d / d) + 4 *\n      sum(d * f_d * right_mult)\n    -2 * tau2 * prod(p) + sum(max_d_lambda ^ 2) + 2 * tau2 * div_f\n}\n\n##' SURE for spectral shrinkage functions for real matrices.\n##'\n##' Only works for soft thresholding.\n##'\n##' @param d A vector of numerics. The singular values.\n##' @param lambda A numeric. The shrinkage parameter.\n##' @param p A vector of positive integers. The dimension of the data array.\n##' @param tau2 A positive numeric. The variance. Assumed known and defaults to\n##'   1.\n##'\n##' @author David Gerard.\n##'\n##' @references Candes, E., Sing-Long, C. A., & Trzasko, J. D. (2013).\n##'   \\href{http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6545395&tag=1}{Unbiased\n##'    risk estimates for singular value thresholding and spectral estimators}.\n##'   \\emph{Signal Processing, IEEE Transactions on}, 61(19), 4643-4657.\n##'\n##' @export\nsure_matrix <- function(d, lambda, p_dim, tau2 = 1) {\n\n    f_d <- pos_part(d - lambda)\n    df_d <- 1 * (d > lambda)\n\n    max_d_lambda <- sapply(d, min, lambda)\n    outer_temp <- 1 / outer(d ^ 2, d ^ 2, \"-\")\n    diag(outer_temp) <- 0\n    right_mult <- apply(outer_temp, 1, sum)\n    ##div_f <- sum(df_d + abs(p_dim[1] - p_dim[2]) *\n    ##              pos_part(1 - lambda / d)) + 2 *\n    ## sum(d * f_d * right_mult)\n    div_f <- sum(df_d + abs(p_dim[1] - p_dim[2]) * f_d / d) +\n      2 * sum(d * f_d * right_mult)\n    -tau2 * prod(p_dim) + sum(max_d_lambda ^ 2) + 2 * tau2 * div_f\n}\n\n##' Min Efron-Morris estimator.\n##'\n##' @param X An array of numerics. The data tensor.\n##' @param tau2 A positive numeric. The variance. Assumed known and defaults to\n##'   1.\n##'\n##' @author David Gerard\n##'\n##' @references Efron, B., & Morris, C. (1972).\n##'   \\href{http://biomet.oxfordjournals.org/content/59/2/335.short}{Empirical\n##'   Bayes on vector observations: An extension of Stein's method}.\n##'   \\emph{Biometrika}, 59(2), 335-347.\n##'\n##' @export\nmin_ef <- function(X, tau2 = 1) {\n    ## minimizes SURE of efron-moris estimator along each mode\n    p <- dim(X)\n    n <- length(p)\n    ef_est <- list()\n    sure_vec <- rep(NA, length = n)\n    for (mode_index in 1:n) {\n        S_k_inv <- solve(tensr::mat(X, mode_index) %*%\n                           t(tensr::mat(X, mode_index)))\n        sure_vec[mode_index] <- tau2 * 1 -\n          (prod(p[-mode_index]) - p[mode_index] - 1) ^ 2 *\n          tau2 ^ 2 / prod(p) * sum(diag(S_k_inv))\n        ef_est[[mode_index]] <-\n          tensr::amprod(X, (diag(p[mode_index]) -\n                              tau2 * (prod(p[-mode_index]) - p[mode_index] - 1) *\n                              S_k_inv), mode_index)\n    }\n    winner <- which.min(sure_vec)\n    return(list(ef_est = ef_est[[winner]], sure = prod(p) * sure_vec[winner]))\n}\n\n##' Efron-Morris estimator.\n##'\n##' @inheritParams min_ef\n##' @param mode_index The mode upon which to apply the Efron-Morris estimator.\n##'   Defaults to the first mode.\n##'\n##' @author David Gerard.\n##'\n##' @references Efron, B., & Morris, C. (1972).\n##'   \\href{http://biomet.oxfordjournals.org/content/59/2/335.short}{Empirical\n##'   Bayes on vector observations: An extension of Stein's method}.\n##'   \\emph{Biometrika}, 59(2), 335-347.\n##'\n##' @export\nefron_morris <- function(X, mode_index = 1, tau2 = 1) {\n    p <- dim(X)\n    S_k_inv <- solve(tensr::mat(X, mode_index) %*%\n                       t(tensr::mat(X, mode_index)))\n    ef_est <- tensr::amprod(X, (diag(p[mode_index]) - tau2 *\n                                  (prod(p[-mode_index]) - p[mode_index] - 1) *\n                                  S_k_inv), mode_index)\n    sure_val <- tau2 * 1 - (prod(p[-mode_index]) - p[mode_index] - 1) ^ 2 *\n      tau2 ^ 2 / prod(p) * sum(diag(S_k_inv))\n    return(list(ef_est = ef_est, sure = prod(p) * sure_val))\n}\n\n##' Stein's estimator.\n##'\n##' @param X A vector, matrix, or array of numerics. The data.\n##' @param tau2 A positive numeric. The variance. Assumed known and defaults to\n##'   1.\n##'\n##' @author David Gerard.\n##'\n##' @references James, W., & Stein, C. (1961, June).\n##'   \\href{http://projecteuclid.org/euclid.bsmsp/1200512173}{Estimation with\n##'   quadratic loss}. \\emph{In Proceedings of the fourth Berkeley symposium on\n##'   mathematical statistics and probability} (Vol. 1, No. 1961, pp. 361-379).\n##'\n##' @export\nstein <- function(X, tau2 = 1) {\n    p <- dim(X)\n    ## returns Stein's estimator\n    sum_x <- sum(X ^ 2)\n    est <- (1 - (prod(p) - 2) * tau2 / sum_x) * X\n    sure_est <- prod(p) * tau2 - (prod(p) - 2) ^ 2 * tau2 ^ 2 / sum_x\n    return(list(est = est, sure_est = sure_est))\n}\n\n\n##' Runs a stochastic gradient descent to minimize SURE for higher-order\n##' spectral estimators.\n##'\n##' This function is in beta. Not sure if it works properly or is even\n##' worthwhile considering that \\code{\\link{soft_coord}} works pretty well.\n##' Also, we have to call \\code{\\link{get_c}} anyway, so not sure if this function\n##' actually reduces the computational complexity.\n##'\n##' @param c_obj = Output from \\code{\\link{get_c}}.\n##' @param sgd_lambda Lambda value from sgd for lambda from hose.\n##' @param sgd_lambda_c Lambda value from sgd for c from hose.\n##' @param c_init Initalization for c from hose.\n##' @param lamda_init Initialization for lambda from hose.\n##' @param sgd_c c value from sgd.\n##' @param itermax Maximum number of iterations for sgd.\n##' @param tau2 Known variance.\n##' @param print_current Should we print the results at each iteration?\n##' @param every_iter If \\code{print_current = TRUE}, then every\n##'   \\code{every_iter} iteration will be printed.\n##' @param alpha Burnin for final estimates.\n##' @param calc_final Should we calculate the final sure and estimates?\n##'\n##' @author David Gerard.\n##'\n##' @references Gerard, D., & Hoff, P. (2015).\n##'   \\href{http://arxiv.org/abs/1505.02114}{Adaptive Higher-order Spectral\n##'   Estimators}. \\emph{arXiv preprint} arXiv:1505.02114.\nsgd_given_c <- function(c_obj, sgd_lambda, sgd_lambda_c, c_init = 1,\n                        lambda_init = NULL, sgd_c = 1 / 2 + 0.001,\n                        itermax = 10000, tau2 = 1, print_current = TRUE,\n                        every_iter = 1000, alpha = 0.2, calc_final = TRUE) {\n    hosvd_x <- c_obj$hosvd_x\n    c_array <- c_obj$C_array\n    p <- dim(c_array)\n    n <- length(p)\n\n    c_current <- c_init\n    if (is.null(lambda_init)) {\n        lambda_current <- rep(0, length = n)\n    } else {\n        lambda_current <- lambda_init\n    }\n\n    lambda_mat <- matrix(NA, nrow = itermax, ncol = n)\n    c_vec <- rep(NA, length = itermax)\n    for (sgd_index in 1:itermax) {\n        max_toget <- rep(NA, length = n)\n        for (mode_index in 1:n) {\n            max_toget[mode_index] <-\n              sum(hosvd_x$D[[mode_index]] > lambda_current[mode_index])\n        }\n\n\n        ## use bernoulli to see if I draw a 0 for gradient\n        p_1 <- prod(max_toget) / prod(p)\n        is_0 <- rbinom(1, 1, 1 - p_1)\n\n        if (is_0 == 1) {\n            lambda_new <- lambda_current\n            c_new <- c_current\n            lambda_mat[sgd_index, ] <- lambda_new\n            c_vec[sgd_index] <- c_new\n        } else {\n            index_current <- c()\n            for (mode_index in 1:n) {\n                index_current <-\n                  c(index_current, sample(1:max_toget[mode_index], size = 1))\n            }\n\n            sigma_current <- c()\n            f_current <- c()\n            for (mode_index in 1:n) {\n                sigma_current[mode_index] <-\n                  hosvd_x$D[[mode_index]][index_current[mode_index]]\n                f_current[mode_index] <- f_lasso(sigma_current[mode_index],\n                                                 lambda_current[mode_index])\n            }\n\n            f_times_sigma_inv <- f_current / sigma_current\n            f_s_mult <- prod(f_times_sigma_inv)\n            S2_current <- hosvd_x$S[matrix(index_current, nrow = 1)] ^ 2\n            C_array_current <- c_array[matrix(index_current, nrow = 1)]\n\n            common_to_all <- -c_current * f_s_mult ^ 2 * S2_current + f_s_mult *\n              S2_current - tau2 * f_s_mult * C_array_current\n\n            inv_temp <-\n              matrix(rep(1 / (f_current * sigma_current), n), nrow = n)\n            diag(inv_temp) <- 0\n\n            grad_current_lambda <- 2 * c_current *\n              (common_to_all - colSums(inv_temp) *\n                 tau2 * f_s_mult * S2_current) / f_current\n\n            step_size <- sgd_c / (sgd_lambda * sgd_index)\n\n            lambda_new <- lambda_current - step_size * grad_current_lambda\n\n\n            grad_c <- 2 * c_current * f_s_mult ^ 2 * S2_current -\n              2 * f_s_mult * S2_current +\n              2 * tau2 * f_s_mult * C_array_current + 2 * tau2 * f_s_mult *\n              S2_current * sum(1 / (f_current * sigma_current))\n\n            step_size_c <- sgd_c / (sgd_lambda_c * sgd_index)\n            c_new <- c_current - grad_c * step_size_c\n\n\n            lambda_mat[sgd_index, ] <- lambda_new\n            c_vec[sgd_index] <- c_new\n\n            c_current <- c_new\n            lambda_current <- lambda_new\n        }\n\n        if (print_current & (sgd_index %% every_iter == 0)) {\n            cat(\"Current Lambda = \", lambda_current, \"\\n\")\n            cat(\"     Current c = \", c_current, \"\\n\")\n            cat(\"     Grad of c = \", grad_c, \"\\n\")\n            cat(\"Grad of lambda = \", grad_current_lambda, \"\\n\\n\")\n        }\n    }\n\n    if (calc_final) {\n        ## get final estimates\n        c_final <- mean(c_vec[round(alpha * itermax):itermax])\n        lambda_final <- colMeans(lambda_mat[round(alpha * itermax):itermax, ])\n        lambda_list <- list()\n        lambda_list[[1]] <- c(lambda_final[1], c_final)\n        func_lasso <- list()\n        dfunc_lasso <- list()\n        func_lasso[[1]] <- f_lasso_mult\n        dfunc_lasso[[1]] <- df_lasso_mult\n        for (mode_index in 2:n) {\n            lambda_list[[mode_index]] <- lambda_final[mode_index]\n            func_lasso[[mode_index]] <- f_lasso\n            dfunc_lasso[[mode_index]] <- df_lasso\n        }\n        sure_est <- sure_given_c(c_obj, func = func_lasso, dfunc = dfunc_lasso,\n                                 lambda = lambda_list, tau2 = tau2)\n        return(list(c_vec = c_vec, lambda_mat = lambda_mat, c_final = c_final,\n                    lambda_final = lambda_final, sure_final = sure_est))\n    } else {\n        return(list(c_vec = c_vec, lambda_mat = lambda_mat))\n    }\n}\n\n\n\n## Block SURE methods this first one overlaps all pixels and circles back\n\n##' Adds a circular padding after matrix.\n##'\n##' @param X A matrix of numerics.\n##' @param padsize A positive integer. The number of columns/rows to add to\n##'   \\code{X}.\n##'\n##' @author David Gerard.\n##'\n##' @export\npad_circ <- function(X, padsize) {\n    p <- dim(X)\n    Y <- matrix(NA, nrow = p[1] + padsize, ncol = p[2] + padsize)\n    Y[1:p[1], 1:p[2]] <- X\n    Y[1:p[1], (p[2] + 1):(p[2] + padsize)] <- X[1:p[1], 1:padsize]\n    Y[(p[1] + 1):(p[1] + padsize), 1:p[2]] <- X[1:padsize, 1:p[2]]\n    Y[(p[1] + 1):(p[1] + padsize), (p[2] + 1):(p[2] + padsize)] <-\n      X[1:padsize, 1:padsize]\n    return(Y)\n}\n\n##' Calculates the necessary components to calculate the SURE for estimators\n##' that block shrink overlapping blocks.\n##'\n##' @param current_tensor An array of numerics.\n##' @param block_size The size of the overlapping blocks.\n##' @param p The dimension of \\code{current_tensor}.\n##'\n##' @return A list of elements used in \\code{\\link{block_sure_given_c_list}} to\n##'   calculate the SURE.\n##'\n##' @seealso \\code{\\link{block_sure_given_c_list}}, \\code{\\link{block_sure}}.\n##'\n##' @author David Gerard.\n##'\n##' @references Gerard, D., & Hoff, P. (2015).\n##'   \\href{http://arxiv.org/abs/1505.02114}{Adaptive Higher-order Spectral\n##'   Estimators}. \\emph{arXiv preprint} arXiv:1505.02114.\n##'\n##' @export\nget_c_list <- function(current_tensor, block_size = dim(current_tensor)[3]) {\n    p <- dim(current_tensor)\n    ##n <- length(p) ## may not be used.\n\n    tensor_expanded <- array(NA, dim = c(p[1] + block_size - 1,\n                                         p[2] + block_size - 1, p[3]))\n    for (frame_index in 1:p[3]) {\n        mat_expanded <- pad_circ(current_tensor[, , frame_index],\n                                 padsize = block_size - 1)\n        tensor_expanded[, , frame_index] <- mat_expanded\n    }\n\n    c_list <- list()\n    block_list <- list()\n    overall_index <- 1\n    for (x_index in 1:p[1]) {\n        for (y_index in 1:p[2]) {\n            block_list[[overall_index]] <-\n              tensor_expanded[x_index:(block_size + x_index - 1),\n                              y_index:(block_size + y_index - 1), ]\n            c_list[[overall_index]] <- get_c(block_list[[overall_index]])\n            overall_index <- overall_index + 1\n        }\n    }\n    return(list(c_list = c_list, block_list = block_list,\n                tensor_expanded = tensor_expanded,\n                current_tensor = current_tensor, block_size = block_size,\n                p = p))\n}\n\n##' Calculates the sure of estimators that shrink subtensors using the output of\n##' \\code{\\link{get_c_list}}.\n##'\n##' @param c_obj The output from \\code{\\link{get_c_list}}.\n##' @param func A list of functions to apply to each mode.\n##' @param dfunc A list of derivatives of the function in \\code{func}.\n##' @param lambda_list A list of parameter values for \\code{func} and\n##'   \\code{dfunc}.\n##' @param tau2 A positive numeric. The variance. Assumed known and defaults to\n##'   1.\n##'\n##' @return \\code{sure_final} A numeric. The SURE value.\n##'\n##' \\code{mean_est} An array of numerics. The mean estimate.\n##'\n##' @seealso \\code{\\link{get_c_list}}, \\code{\\link{block_sure}}.\n##'\n##' @author David Gerard.\n##'\n##' @references Gerard, D., & Hoff, P. (2015).\n##'   \\href{http://arxiv.org/abs/1505.02114}{Adaptive Higher-order Spectral\n##'   Estimators}. \\emph{arXiv preprint} arXiv:1505.02114.\n##'\n##' @export\nblock_sure_given_c_list <- function(c_obj, func, dfunc, lambda_list,\n                                    tau2 = 1) {\n    tensor_expanded <- c_obj$tensor_expanded\n    c_list <- c_obj$c_list\n    ##block_list <- c_obj$block_list ## may not be used\n    block_size <- c_obj$block_size\n    current_tensor <- c_obj$current_tensor\n    p <- c_obj$p\n    ##n <- length(p) ## may not be used.\n\n    p2 <- dim(tensor_expanded)\n\n    overall_index <- 1\n    diverge_tot <- 0\n    est_tot1 <- array(0, dim = p2)\n    for (x_index in 1:p[1]) {\n        for (y_index in 1:p[2]) {\n            div_current <- diverge_given_c(c_list[[overall_index]],\n                                           func = func, dfunc = dfunc,\n                                           lambda = lambda_list)\n            diverge_tot <- diverge_tot + div_current$divergence_f\n            est_tot1[x_index:(block_size + x_index - 1),\n                     y_index:(block_size + y_index - 1), ] <-\n              est_tot1[x_index:(block_size + x_index - 1),\n                       y_index:(block_size + y_index - 1), ] +\n              div_current$mean_est\n            overall_index <- overall_index + 1\n        }\n    }\n\n    est_tot <- est_tot1[1:p[1], 1:p[2], ]\n\n    est_tot[1:(block_size - 1), 1:(block_size - 1), ] <-\n      est_tot[1:(block_size - 1), 1:(block_size - 1), ] +\n      est_tot1[(p[1] + 1):(p[1] + block_size - 1),\n               (p[2] + 1):(p[2] + block_size - 1), ]\n    est_tot[1:(block_size - 1), 1:p[2], ] <-\n      est_tot[1:(block_size - 1), 1:p[2], ] +\n      est_tot1[(p[1] + 1):(p[1] + block_size - 1), 1:p[2], ]\n    est_tot[1:p[1], 1:(block_size - 1), ] <-\n      est_tot[1:p[1], 1:(block_size - 1), ] +\n      est_tot1[1:p[1], (p[2] + 1):(p[2] + block_size - 1), ]\n\n    ## because reusing each pixel block_size^2 times.\n    est_tot <- est_tot / block_size ^ 2\n    diverge_tot <- diverge_tot / block_size ^ 2\n\n    sure_final <- sum( (est_tot - current_tensor) ^ 2) - tau2 * prod(p) +\n      2 * tau2 * diverge_tot\n    return(list(sure_final = sure_final, mean_est = est_tot))\n}\n\n##' Wrapper for \\code{\\link{get_c_list}} and\n##' \\code{\\link{block_sure_given_c_list}}.\n##'\n##' @inheritParams get_c_list\n##' @inheritParams block_sure_given_c_list\n##'\n##' @return \\code{sure_final} A numeric. The SURE value.\n##'\n##' \\code{mean_est} An array of numerics. The mean estimate.\n##'\n##' @author David Gerard.\n##'\n##' @references Gerard, D., & Hoff, P. (2015).\n##' \\href{http://arxiv.org/abs/1505.02114}{Adaptive Higher-order Spectral Estimators}.\n##' \\emph{arXiv preprint} arXiv:1505.02114.\n##'\n##' @export\nblock_sure <- function(current_tensor, func, dfunc, lambda_list, tau2 = 1,\n                       block_size = dim(current_tensor)[3]) {\n    c_obj <- get_c_list(current_tensor, block_size = block_size)\n    block_sure_given_c_list(c_obj, func = func, dfunc = dfunc,\n                            lambda_list = lambda_list, tau2)\n}\n\n\n###### now for block SURE with non-overlapping blocks doesn't work if p_k %%\n###### block_size = 1 for either k = 1 or 2\n\n##' Calculates the necessary components to calculate the SURE for estimators\n##' that shrink non-overlapping sub-tensors.\n##'\n##' @param current_tensor An array of numerics.\n##' @param block_size The size of the non-overlapping blocks.\n##'\n##' @return A list of elements used in \\code{\\link{block_sure_given_c_list_non}}\n##'   to calculate the SURE.\n##'\n##' @seealso \\code{\\link{block_sure_given_c_list_non}},\n##'   \\code{\\link{block_sure_non}}\n##'\n##' @author David Gerard.\n##'\n##' @references Gerard, D., & Hoff, P. (2015).\n##'   \\href{http://arxiv.org/abs/1505.02114}{Adaptive Higher-order Spectral\n##'   Estimators}. \\emph{arXiv preprint} arXiv:1505.02114.\n##'\n##' @export\nget_c_list_non <- function(current_tensor,\n                           block_size = dim(current_tensor)[3]) {\n    ## same as get_c_list but with non-overlapping blocks\n    p <- dim(current_tensor)\n    ##n <- length(p) ## may not be used.\n\n    c_list <- list()\n    block_list <- list()\n    overall_index <- 1\n\n    x_max <- floor(p[1] / block_size)\n    y_max <- floor(p[2] / block_size)\n    for (x_index in 1:(x_max + 1)) {\n        for (y_index in 1:(y_max + 1)) {\n            if (y_index < (y_max + 1) & x_index < (x_max + 1)) {\n                block_list[[overall_index]] <-\n                  current_tensor[( (x_index - 1) * block_size + 1):(x_index * block_size),\n                                 ( (y_index - 1) * block_size + 1):(y_index * block_size), ]\n                c_list[[overall_index]] <- get_c(block_list[[overall_index]])\n                overall_index <- overall_index + 1\n            } else if (y_index < (y_max + 1) & x_index == (x_max + 1)) {\n                block_list[[overall_index]] <-\n                  current_tensor[( (x_index - 1) * block_size + 1):p[1],\n                                 ( (y_index - 1) * block_size + 1):(y_index * block_size), ]\n                c_list[[overall_index]] <- get_c(block_list[[overall_index]])\n                overall_index <- overall_index + 1\n            } else if (y_index == (y_max + 1) & x_index < (x_max + 1)) {\n                block_list[[overall_index]] <-\n                  current_tensor[( (x_index - 1) * block_size + 1):(x_index * block_size),\n                                 ( (y_index - 1) * block_size + 1):p[2], ]\n                c_list[[overall_index]] <- get_c(block_list[[overall_index]])\n                overall_index <- overall_index + 1\n            } else {\n                block_list[[overall_index]] <-\n                  current_tensor[( (x_index - 1) * block_size + 1):p[1],\n                                 ( (y_index - 1) * block_size + 1):p[2], ]\n                c_list[[overall_index]] <- get_c(block_list[[overall_index]])\n                overall_index <- overall_index + 1\n            }\n        }\n    }\n    return(list(c_list = c_list, block_list = block_list,\n                current_tensor = current_tensor, block_size = block_size))\n}\n\n##' Calculates the SURE of estimators that shrink non-overlapping sub-tensors\n##' using the output of \\code{\\link{get_c_list_non}}.\n##'\n##' @param c_obj The output from \\code{\\link{get_c_list}}.\n##' @param func A list of functions to apply to each mode.\n##' @param dfunc A list of derivatives of the function in \\code{func}.\n##' @param lambda_list A list of parameter values for \\code{func} and\n##'   \\code{dfunc}.\n##' @param tau2 A positive numeric. The variance. Assumed known and defaults to\n##'   1.\n##'\n##' @return \\code{sure_final} A numeric. The SURE value.\n##'\n##'   \\code{mean_est} An array of numerics. The mean estimate.\n##'\n##' @seealso \\code{\\link{get_c_list_non}}, \\code{\\link{block_sure_non}}.\n##'\n##' @author David Gerard.\n##'\n##' @references Gerard, D., & Hoff, P. (2015).\n##'   \\href{http://arxiv.org/abs/1505.02114}{Adaptive Higher-order Spectral\n##'   Estimators}. \\emph{arXiv preprint} arXiv:1505.02114.\n##'\n##' @export\nblock_sure_given_c_list_non <- function(c_obj, func, dfunc, lambda_list,\n                                        tau2 = 1) {\n    current_tensor <- c_obj$current_tensor\n    c_list <- c_obj$c_list\n    ##block_list <- c_obj$block_list ## may not be used.\n    block_size <- c_obj$block_size\n    p <- dim(current_tensor)\n    ##n <- length(p) ## may not be used.\n\n    overall_index <- 1\n    diverge_tot <- 0\n    est_tot <- array(0, dim = p)\n    x_max <- floor(p[1] / block_size)\n    y_max <- floor(p[2] / block_size)\n    for (x_index in 1:(x_max + 1)) {\n        for (y_index in 1:(y_max + 1)) {\n            if (y_index < (y_max + 1) & x_index < (x_max + 1)) {\n                div_current <- diverge_given_c(c_list[[overall_index]],\n                                               func = func, dfunc = dfunc,\n                                               lambda = lambda_list)\n                diverge_tot <- diverge_tot + div_current$divergence_f\n                est_tot[( (x_index - 1) * block_size + 1):(x_index * block_size),\n                        ( (y_index - 1) * block_size + 1):(y_index * block_size), ] <-\n                  div_current$mean_est\n                overall_index <- overall_index + 1\n            } else if (y_index < (y_max + 1) & x_index == (x_max + 1)) {\n                div_current <- diverge_given_c(c_list[[overall_index]],\n                                               func = func, dfunc = dfunc,\n                                               lambda = lambda_list)\n                diverge_tot <- diverge_tot + div_current$divergence_f\n                est_tot[( (x_index - 1) * block_size + 1):p[1],\n                        ( (y_index - 1) * block_size + 1):(y_index * block_size), ] <-\n                  div_current$mean_est\n                overall_index <- overall_index + 1\n            } else if (y_index == (y_max + 1) & x_index < (x_max + 1)) {\n                div_current <- diverge_given_c(c_list[[overall_index]],\n                                               func = func, dfunc = dfunc,\n                                               lambda = lambda_list)\n                diverge_tot <- diverge_tot + div_current$divergence_f\n                est_tot[( (x_index - 1) * block_size + 1):(x_index * block_size),\n                        ( (y_index - 1) * block_size + 1):p[2], ] <-\n                  div_current$mean_est\n                overall_index <- overall_index + 1\n            } else {\n                div_current <-\n                  diverge_given_c(c_list[[overall_index]],\n                                  func = func, dfunc = dfunc,\n                                  lambda = lambda_list)\n                diverge_tot <- diverge_tot + div_current$divergence_f\n                est_tot[( (x_index - 1) * block_size + 1):p[1],\n                        ( (y_index - 1) * block_size + 1):p[2], ] <-\n                  div_current$mean_est\n                overall_index <- overall_index + 1\n            }\n        }\n    }\n\n    sure_final <- sum( (est_tot - current_tensor) ^ 2) - tau2 * prod(p) +\n      2 * tau2 * diverge_tot\n    return(list(sure_final = sure_final, mean_est = est_tot))\n}\n\n##' Wrapper for \\code{\\link{get_c_list_non}} and\n##' \\code{\\link{block_sure_given_c_list_non}}.\n##'\n##' @inheritParams get_c_list_non\n##' @inheritParams block_sure_given_c_list_non\n##'\n##' @return \\code{sure_final} A numeric. The SURE value.\n##'\n##'   \\code{mean_est} An array of numerics. The mean estimate.\n##'\n##' @seealso \\code{\\link{get_c_list_non}},\n##'   \\code{\\link{block_sure_given_c_list_non}}.\n##'\n##' @author David Gerard.\n##'\n##' @references Gerard, D., & Hoff, P. (2015).\n##'   \\href{http://arxiv.org/abs/1505.02114}{Adaptive Higher-order Spectral\n##'   Estimators}. \\emph{arXiv preprint} arXiv:1505.02114.\n##'\n##' @export\nblock_sure_non <- function(current_tensor, func, dfunc, lambda_list, tau2 = 1,\n                           block_size = dim(current_tensor)[3]) {\n    c_obj <- get_c_list_non(current_tensor, block_size = block_size)\n    block_sure_given_c_list_non(c_obj, func = func, dfunc = dfunc,\n                                lambda_list = lambda_list, tau2)\n}\n\n\n## Coordinate Descent for Soft Thresholding ---------------------------\n\n##' Update of thresholding parameter for scale and soft-thresholding HOSEs.\n##'\n##' @param c_obj The output from \\code{\\link{get_c}}.\n##' @param lambda_current A vector of numerics of length \\eqn{n}. The current\n##'   values for the thresholding parameters.\n##' @param c_current A positive numeric. The current value of the scaling\n##'   parameter.\n##' @param k A positive integer. The mode to update.\n##' @param tau2 A positive numeric. The variance. Assumed known and defaults to\n##'   1.\n##' @param epsilon A positive numeric. The min distance of the Newton update.\n##'\n##' @return \\code{lambda_new} A numeric. The update of the threshholding\n##'   parameter.\n##'\n##' @seealso \\code{\\link{soft_coord}}.\n##'\n##' @author David Gerard.\n##'\n##' @references Gerard, D., & Hoff, P. (2015).\n##'   \\href{http://arxiv.org/abs/1505.02114}{Adaptive Higher-order Spectral\n##'   Estimators}. \\emph{arXiv preprint} arXiv:1505.02114.\n##'\n##' @export\nupdate_lambda <- function(c_obj, lambda_current, c_current, k, tau2,\n                          epsilon = 10 ^ -4) {\n    ## k = current mode to update\n    hosvd_x <- c_obj$hosvd_x\n    C_array <- c_obj$C_array\n    S <- hosvd_x$S\n    p <- dim(S)\n    n <- length(p)\n\n    sig <- hosvd_x$D\n\n    max_toget <- rep(NA, length = n)\n    for (mode_index in 1:n) {\n        max_toget[mode_index] <-\n          sum(sig[[mode_index]] > lambda_current[mode_index])\n    }\n\n    if (any(max_toget == 0)) {\n        stop(\"Regularization is too large\")\n    }\n\n    indices_toget <- as.matrix(expand.grid(lapply(max_toget, seq, from = 1)))\n    C_sub <- array(C_array[indices_toget], dim = max_toget)\n    S_sub <- array(S[indices_toget], dim = max_toget)\n\n    f_d <- list()\n    sig_sub <- list()\n    one_over_f_sig <- list()\n    for (mode_index in 1:n) {\n        sig_sub[[mode_index]] <- sig[[mode_index]][1:max_toget[mode_index]]\n        f_d[[mode_index]] <- sig_sub[[mode_index]] - lambda_current[mode_index]\n        one_over_f_sig[[mode_index]] <-\n          1 / (f_d[[mode_index]] * sig_sub[[mode_index]])\n    }\n    one_over_f_sig[[k]] <- rep(0, max_toget[k])\n\n\n\n    sig_ik_list <- lapply(max_toget, rep, x = 1)\n    sig_ik_list[[k]] <- sig_sub[[k]]\n\n    f_d_ones_added <- f_d\n    f_d_ones_added[[k]] <- rep(1, length = max_toget[k])\n    f_sig_inv_array <- f_d_ones_added[[1]] / sig_sub[[1]]\n    ratio_array <- one_over_f_sig[[1]]\n    sig_ik_array <- sig_ik_list[[1]]\n    for (mode_index in 2:n) {\n        f_sig_inv_array <-\n          outer(f_sig_inv_array,\n                f_d_ones_added[[mode_index]] / sig_sub[[mode_index]])\n        ratio_array <-\n          outer(ratio_array, one_over_f_sig[[mode_index]], FUN = \"+\")\n        sig_ik_array <- outer(sig_ik_array, sig_ik_list[[mode_index]])\n    }\n\n    b <- sum(c_current * f_sig_inv_array * S_sub ^ 2)\n    e <- sum(tau2 * c_current * f_sig_inv_array * C_sub)\n    d <- sum(tau2 * c_current * f_sig_inv_array * S_sub ^ 2 * ratio_array)\n    a_1 <- sum(c_current ^ 2 * f_sig_inv_array ^ 2 * sig_ik_array * S_sub ^ 2)\n    a_2 <- sum(c_current ^ 2 * f_sig_inv_array ^ 2 * S_sub ^ 2)\n\n    lambda_new <- min( (a_1 + e + d - b) / a_2, max(sig[[k]]) - epsilon)\n    if (lambda_new < 0) {\n        lambda_new <- 0\n    }\n    return(lambda_new)\n}\n\n##' Update scale parameter in scale and soft-thresholding HOSE's.\n##'\n##' @param c_obj The output from \\code{\\link{get_c}}.\n##' @param lambda_current A vector of numerics of length \\eqn{n}. The initial\n##'   starting values for the thresholding parameters.\n##' @param c_current A positive numeric. The starting value of the scaling\n##'   parameter.\n##' @param epsilon A positive numeric. The min distance of the Newton update.\n##' @param tau2 A positive numeric. The variance. Assumed known and defaults to\n##'   1.\n##'\n##' @return \\code{c_new} A postive numeric. The update of the scaling parameter.\n##'\n##' @seealso \\code{\\link{soft_coord}}.\n##'\n##' @author David Gerard.\n##'\n##' @references Gerard, D., & Hoff, P. (2015).\n##'   \\href{http://arxiv.org/abs/1505.02114}{Adaptive Higher-order Spectral\n##'   Estimators}. \\emph{arXiv preprint} arXiv:1505.02114.\n##'\n##' @export\nupdate_c <- function(c_obj, lambda_current, c_current, tau2,\n                     epsilon = 10 ^ -4) {\n    hosvd_x <- c_obj$hosvd_x\n    C_array <- c_obj$C_array\n    S <- hosvd_x$S\n    p <- dim(S)\n    n <- length(p)\n\n    sig <- hosvd_x$D\n\n    max_toget <- rep(NA, length = n)\n    for (mode_index in 1:n) {\n        max_toget[mode_index] <-\n          sum(sig[[mode_index]] > lambda_current[mode_index])\n    }\n\n    indices_toget <- as.matrix(expand.grid(lapply(max_toget, seq, from = 1)))\n    C_sub <- array(C_array[indices_toget], dim = max_toget)\n    S_sub <- array(S[indices_toget], dim = max_toget)\n\n    f_d <- list()\n    sig_sub <- list()\n    for (mode_index in 1:n) {\n        sig_sub[[mode_index]] <- sig[[mode_index]][1:max_toget[mode_index]]\n        f_d[[mode_index]] <- sig_sub[[mode_index]] - lambda_current[mode_index]\n    }\n\n    f_sig_inv_array <- f_d[[1]] / sig_sub[[1]]\n    ratio_array <- 1 / (f_d[[1]] * sig_sub[[1]])\n    for (mode_index in 2:n) {\n        f_sig_inv_array <-\n          outer(f_sig_inv_array, f_d[[mode_index]] / sig_sub[[mode_index]])\n        ratio_array <-\n          outer(ratio_array,\n                1 / (f_d[[mode_index]] * sig_sub[[mode_index]]), FUN = \"+\")\n    }\n\n    a <- sum(f_sig_inv_array ^ 2 * S_sub ^ 2)\n    b <- sum(f_sig_inv_array * S_sub ^ 2)\n    d <- sum(tau2 * f_sig_inv_array * C_sub)\n    e <- sum(tau2 * f_sig_inv_array * S_sub ^ 2 * ratio_array)\n\n    c_new <- max( (b - d - e) / a, epsilon)\n    return(c_new)\n}\n\n##' Runs an iterative coordinate descent algorithm to minimize the SURE for\n##' mode-specific soft thresholding estimators.\n##'\n##' @param c_obj The output from \\code{\\link{get_c}}.\n##' @param lambda_init A vector of numerics of length \\eqn{n}. The initial\n##'   starting values for the thresholding parameters.\n##' @param c_init A positive numeric. The starting value of the scaling\n##'   parameter.\n##' @param itermax A positive integer. The maximum number of Newton steps to\n##'   iterate through.\n##' @param tol A positive numeric. The stopping criterion.\n##' @param print_iter A logical. Should we print the updates of the Newton Step?\n##' @param tau2 A positive numeric. The variance. Assumed known and defaults to\n##'   1.\n##' @param use_sure A logical. Which stopping criterion should we use? The mean\n##'   absolute difference in the parameters (\\code{FALSE}) or the absolute value\n##'   of the deviation of the ratio of adjacent SURE values from 1\n##'   (\\code{TRUE}).\n##'\n##' @return \\code{c} A numeric. The final value of the scaling parameter.\n##'\n##'   \\code{lambda} A vector of numerics. The final values of the thresholding\n##'   parameters.\n##'\n##'   \\code{est} An array of numerics. The final mean estimate.\n##'\n##' @author David Gerard.\n##'\n##' @seealso \\code{\\link{update_c}}, \\code{\\link{update_lambda}},\n##'   \\code{\\link{get_c}}.\n##'\n##' @references Gerard, D., & Hoff, P. (2015).\n##'   \\href{http://arxiv.org/abs/1505.02114}{Adaptive Higher-order Spectral\n##'   Estimators}. \\emph{arXiv preprint} arXiv:1505.02114.\n##'\n##' @export\nsoft_coord <- function(c_obj, lambda_init, c_init, itermax = 1000,\n                       tol = 10 ^ -4, print_iter = TRUE, tau2 = 1,\n                       use_sure = TRUE) {\n    hosvd_x <- c_obj$hosvd_x\n    ##C_array <- c_obj$C_array ## may not be used.\n    S <- hosvd_x$S\n    p <- dim(S)\n    n <- length(p)\n\n\n    func_lasso <- list()\n    dfunc_lasso <- list()\n    func_lasso[[1]] <- f_lasso_mult\n    dfunc_lasso[[1]] <- df_lasso_mult\n    for (mode_index in 2:n) {\n        func_lasso[[mode_index]] <- f_lasso\n        dfunc_lasso[[mode_index]] <- df_lasso\n    }\n\n\n    lambda_current <- lambda_init\n    c_current <- c_init\n    current_sure <- prod(p)\n    iter_index <- 1\n    error_all <- tol + 1\n    while (error_all > tol & iter_index < itermax) {\n        c_old <- c_current\n        lambda_old <- lambda_current\n        for (k in 1:n) {\n            lambda_current[k] <-\n              update_lambda(c_obj, lambda_current, c_current, k, tau2)\n        }\n        c_current <- update_c(c_obj, lambda_current, c_current, tau2)\n\n        if (use_sure) {\n            old_sure <- current_sure\n            lambda_list <- list()\n            lambda_list[[1]] <- c(lambda_current[1], c_current)\n            for (mode_index in 2:n) {\n                lambda_list[[mode_index]] <- lambda_current[mode_index]\n            }\n            current_sure <-\n              sure_given_c(c_obj, func_lasso, dfunc_lasso,\n                           lambda = lambda_list, tau2 = tau2)$sure_val\n            cat(\"     SURE =\", round(current_sure, digits = 2), \"\\n\")\n            error_all <- abs(1 - current_sure / old_sure)\n        } else {\n            error_all <- sum(abs(lambda_current - lambda_old)) +\n              abs(1 - c_current / c_old)\n        }\n\n        if (print_iter) {\n            cat(\"Iteration =\", iter_index, \"\\n\")\n            cat(\"        c =\", round(c_current, digits = 2), \"\\n\")\n            cat(\"   Lambda =\",\n                paste(\"(\", paste(round(lambda_current, digits = 2),\n                                 collapse = \",\"), \")\", sep = \"\"), \"\\n\\n\")\n        }\n        iter_index <- iter_index + 1\n    }\n\n    ## Get final mean estimate.\n    param_list <- list()\n    param_list[[1]] <- c(lambda_current[1], c_current)\n    for (mode_index in 2:n) {\n      param_list[[mode_index]] <- lambda_current[mode_index]\n    }\n    est <- sure_given_c(obj = c_obj, func = func_lasso, dfunc = dfunc_lasso,\n                        lambda = param_list, tau2 = tau2)$mean_est\n\n    return(list(c = c_current, lambda = lambda_current, est = est))\n}\n",
    "created" : 1454974153719.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1121604566",
    "id" : "BA7F5266",
    "lastKnownWriteTime" : 1455046509,
    "last_content_update" : 1455046509769,
    "path" : "~/Dropbox/hose/R/tensor_sure.R",
    "project_path" : "R/tensor_sure.R",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}